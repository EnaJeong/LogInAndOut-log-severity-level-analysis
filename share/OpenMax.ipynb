{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"OpenMax.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"d8bc437a"},"source":["import pickle\n","import pandas as pd\n","import numpy as np\n","import scipy.spatial.distance as spd\n","import libmr\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Model\n","from sklearn.metrics import f1_score"],"id":"d8bc437a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"90a19a0b","outputId":"6233a4bb-e772-4c97-abd5-f072243f4a51"},"source":["DIR = './data'\n","MASKING_VER = 'masked_02_drop'\n","\n","train = pd.read_csv(f'{DIR}/train_{MASKING_VER}.csv', index_col=0)\n","submission = pd.read_csv(f'{DIR}/sample_submission.csv', index_col=0)\n","\n","with open(f\"{DIR}/train_padded_{MASKING_VER}.pickle\", \"rb\") as f:\n","    train_padded = pickle.load(f)\n","    \n","with open(f\"{DIR}/valid_padded_{MASKING_VER}.pickle\", \"rb\") as f:\n","    valid_padded = pickle.load(f)\n","    \n","with open(f\"{DIR}/test_padded_{MASKING_VER}.pickle\", \"rb\") as f:\n","    test_padded = pickle.load(f)\n","\n","y_data = train['level']\n","y_train = to_categorical(y_data)"],"id":"90a19a0b","execution_count":null,"outputs":[{"output_type":"stream","text":["C:\\Users\\ASIA-11\\anaconda3\\envs\\prj_final\\lib\\site-packages\\numpy\\lib\\arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  mask |= (ar1 == a)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"9031af3f"},"source":["MODEL_SAVE_FOLDER_PATH = './model'\n","\n","def get_model(file_name):\n","    file = f'{MODEL_SAVE_FOLDER_PATH}/{file_name}.hdf5'\n","    return tf.keras.models.load_model(file)"],"id":"9031af3f","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"972fb84a"},"source":["model = get_model('BI_LSTM_32_16- 9-0.00558-0.99525')\n","new_model = Model(inputs=model.input, outputs=model.layers[-2].output)"],"id":"972fb84a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4e7f44d4"},"source":["categories = range(0, 7)\n","y_true = train['level']\n","scores = new_model.predict(train_padded)"],"id":"4e7f44d4","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7eaeb31b"},"source":["# Functions"],"id":"7eaeb31b"},{"cell_type":"markdown","metadata":{"id":"31f47356"},"source":["## EVT Meta-Recognition"],"id":"31f47356"},{"cell_type":"code","metadata":{"id":"33198fbf"},"source":["def compute_distances(mean_vec, features, eu_scale=200.):\n","    eucos_dist, eu_dist, cos_dist = [], [], []\n","    \n","    for feature in features:\n","        eu = spd.euclidean(mean_vec, feature)\n","        cos = spd.cosine(mean_vec, feature)\n","        \n","        eu_dist.append(eu / eu_scale)\n","        cos_dist.append(cos)\n","        eucos_dist.append(eu / eu_scale + cos)\n","\n","    distances = {'eucos': eucos_dist, 'cosine': cos_dist, 'euclidean':eu_dist}\n","    return distances\n","\n","def compute_mean_distances(categories, y_true, scores, eu_scale=200.):\n","    mean_vectors = {}\n","    distributions = {'eucos': {}, \n","                     'cosine': {}, \n","                     'euclidean': {}}\n","    \n","    y_pred = np.argmax(scores, axis=-1)\n","    \n","    for category in categories:\n","        print('=' * 100)\n","        print(category)\n","        print('=' * 100)\n","\n","        \n","        correct_features = scores[(y_true == category) & (y_pred == y_true)]\n","        \n","        mean_vec = np.mean(correct_features, axis=0)\n","        mean_vectors[category] = mean_vec\n","        print(f'Mean Activation Vector : {mean_vec}')\n","        \n","        distances = compute_distances(mean_vec, correct_features)\n","        for key, distribution in distributions.items():\n","            distribution[category] = distances[key]\n","            \n","        print('=' * 100)\n","        \n","    return mean_vectors, distributions\n","\n","def weibull_tailfitting(categories, means, distances, tailsize=20):\n","    \"\"\" Fit weibull model for each category\n","    \n","    Input:\n","    --------------------------------\n","    means : pre-computed mean-activation vector\n","    distances : pre-computed distances for images from MAV\n","    categories : category list\n","    \n","    Output:\n","    --------------------------------\n","    weibull_model : Perform EVT based analysis using tails of distances and save\n","                    weibull model parameters for re-adjusting softmax scores    \n","    \"\"\"\n","    \n","    weibull_model = {}\n","    \n","    for category in categories:\n","        weibull_model[category] = {}\n","        weibull_model[category]['distances'] = distances[category]\n","        weibull_model[category]['mean_vec'] = means[category]\n","        \n","        mr = libmr.MR()\n","        tailtofit = sorted(distances[category])[-tailsize:]\n","        mr.fit_high(tailtofit, len(tailtofit))\n","        \n","        weibull_model[category]['weibull_model'] = mr\n","\n","    return weibull_model"],"id":"33198fbf","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"65adf6a1"},"source":["## OpenMax"],"id":"65adf6a1"},{"cell_type":"code","metadata":{"id":"cefddb99"},"source":["def compute_distance(query_vec, mean_vec, distance_type='eucos', eu_scale=200.):\n","    \"\"\" Compute the specified distance type between mean vector and query data.\n","    \n","    Input:\n","    --------\n","    query_vec: activation vector of query data\n","    mean_vec: mean activation vector\n","    eu_scale: scaling for eucliean\n","    distance_type: 'eucos', 'euclidean', 'cosine'\n","    \n","    Output:\n","    --------\n","    query_distance : Distance between mean vector and query data\n","    \"\"\"\n","    \n","    if distance_type == 'eucos':\n","        query_distance = spd.euclidean(mean_vec, query_vec) / eu_scale + spd.cosine(mean_vec, query_vec)\n","    elif distance_type == 'euclidean':\n","        query_distance = spd.euclidean(mean_vec, query_vec) / eu_scale\n","    elif distance_type == 'cosine':\n","        query_distance = spd.cosine(mean_vec, query_vec)\n","    else:\n","        assert \"distance type not known: enter either of eucos, euclidean or cosine\"\n","        \n","    return query_distance\n","\n","def compute_softmax(scores):\n","    scores = np.array(scores)\n","    e_x = np.exp(scores - np.max(scores))\n","    probs = e_x / np.sum(e_x)\n","    \n","    return probs.tolist()\n","\n","def recalibrate_scores(weibull_model, categories, scores, alpha=10, distance_type='eucos'):\n","    top_alpha = scores.argsort()[::-1][:alpha]\n","    alpha_weights = np.zeros(len(categories))\n","    alpha_weights[top_alpha] = [((alpha + 1) - i) / alpha for i in range(1, alpha + 1)]\n","        \n","    modified_scores = []\n","    score_unknown = 0\n","\n","    for idx, category in enumerate(categories):\n","        category_weibull = weibull_model[category]\n","        \n","        distance = compute_distance(scores, category_weibull['mean_vec'], distance_type=distance_type)\n","        w_score = category_weibull['weibull_model'].w_score(distance)\n","        modified_score = scores[idx] * (1 - w_score * alpha_weights[idx])\n","        \n","        modified_scores.append(modified_score)\n","        score_unknown += (scores[idx] - modified_score)\n","    \n","    modified_scores.append(score_unknown)\n","    print(modified_scores)\n","    print(scores)\n","    \n","    return compute_softmax(modified_scores)"],"id":"cefddb99","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"17c60656"},"source":["# Calibration"],"id":"17c60656"},{"cell_type":"code","metadata":{"id":"fdd74133"},"source":["WEIBULL_TAIL_SIZE = 20\n","ALPHA_RANK = 3"],"id":"fdd74133","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"f8c99be8"},"source":["mean_vectors, distributions = compute_mean_distances(categories, y_true, scores)"],"id":"f8c99be8","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"1c0f9f5f"},"source":["for key, values in distributions.items():\n","    print(key)\n","    for d in values.values():\n","        print(np.mean(d))"],"id":"1c0f9f5f","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d6b6ad44"},"source":["weibulls = {}\n","\n","for dist_type, distribution in distributions.items():\n","    weibulls[dist_type] = weibull_tailfitting(categories, mean_vectors, distribution, tailsize=WEIBULL_TAIL_SIZE)\n","    \n","print(weibulls.keys())"],"id":"d6b6ad44","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ca9b568"},"source":["DIST_TYPE = 'eucos'\n","\n","weibull_model = weibulls[DIST_TYPE]\n","openmax = recalibrate_scores(weibull_model, categories, scores[0], alpha=ALPHA_RANK, distance_type=DIST_TYPE)\n","\n","print(f\"Softmax Scores {compute_softmax(scores[0])}\")\n","print(f\"Openmax Scores {openmax}\")"],"id":"5ca9b568","execution_count":null,"outputs":[]}]}